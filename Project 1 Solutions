Solutions to ACS Project 1
9/22/2023
Andrew Prata, Naif Jabir

(1) Read and Write Latency for Cache and DRAM
_____________________________________________

Zero queueing delay implies that there is no wait for
data writing or access. This means that the system
should be idling, or as close to idling as possible
to get an accurate reading of unloaded latencies.

The size of the caches for the target processor,
an Intel Core i7-12700K, are as follows:
L1: 1.0 MB
L2: 12.0 MB
L3: 25.0 MB

To test latencies, we will use the MLC commands below:
Testing L1
mlc --idle_latency -b900k

Testing L2
mlc --idle_latency -b11m

Testing L3
mlc --idle_latency -b23m

Testing DRAM
mlc --idle_latency -b60m

These commands yielded the following data, averaged
over three runs each:
L1 Cache Read Latency: 3.93 ns
L2 Cache Read Latency: 16.87 ns
L3 Cache Read Latency: 36.30 ns
DRAM Read Latency:     69.87 ns

Latency for writing to any level of the memory
hierarchy is less than that for reading, under
most circumstances. We are unable to precisely
determine these values, however we can say with
a high degree of certainty that they are less than
or equal to, but no higher than, the Read latencies
that are listed above. This is due to the non-
blocking nature of a memory write, as opposed to the
blocking nature of a read. Reading requires that the
processor wait for a value to be returned from the
memory, however writing does not have this requirement.

(2) DRAM Maximum Bandwidth
__________________________

The Intel MLC uses the size of the allocated buffer
to determine the Bandwidth of a particular memory
hierarchy level. Need to find out the command line
parameters to configure the size of this. Then, can
determine what the latencies of different levels are.
<PAGES 8, 9 OF MLC DOCUMENT>

To test maximum bandwidth, we will use the MLC commands below:
Testing DRAM
Granularity: 64 Bytes
ReadOnly: mlc --max_bandwidth -l64 -R
WriteOnly:mlc --max_bandwidth -l64 -W6
70:30 R:W: mlc--max_bandwidth -l64 -W2
50:50 R:W: mlc --max_bandwidth -l64 -W5

Granularity: 256 Bytes
ReadOnly: mlc --max_bandwidth -l256 -R
WriteOnly:mlc --max_bandwidth -l256 -W6
70:30 R:W: mlc--max_bandwidth -l256 -W2
50:50 R:W: mlc --max_bandwidth -l256 -W5

Granularity: 1024 Bytes
ReadOnly: mlc --max_bandwidth -l1024 -R
WriteOnly:mlc --max_bandwidth -l1024 -W6
70:30 R:W: mlc--max_bandwidth -l1024 -W2
50:50 R:W: mlc --max_bandwidth -l1024 -W5

(3) The Tradeoff Between Latency and Bandwidth of DRAM
There is an inherent trade-off between the latency of
a memory system and the bandwith of the system. As
discussed in class regarding SRAM array implementation,
this is an inversely proportional relationship. A
memory system can be designed to maximize bandwith,
and thus throughput, OR can be optimized for low latency.
With an increase in throughput (moving lots of data
for a given unit of time), there will be negative
impacts to latency due to constraints applied from
semiconductor physics. Additionally, another key
concept from queing theory suggests that a maximally
utilized system correlates with high throughput.
However, the higher that the utilization climbs, the
longer the queue will inevitably become.

(4) Impact of Cache Miss Ratio on Performance


(5) Impact of TLB Miss Ratio on Performance

